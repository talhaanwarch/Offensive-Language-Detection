{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OLIC_Classification_GRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/Offensive-Language-Detection/blob/master/OLID_Transform%20Network%20LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GhlQnoqqBy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "e4261658-0278-4496-934c-b1a32bdb1bc3"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "#!wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
        "##!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ro.300.vec.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-03 20:25:12--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2020-01-03 20:25:17--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2020-01-03 20:25:18--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  1.92MB/s    in 16m 57s \n",
            "\n",
            "2020-01-03 20:42:15 (2.04 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n",
            "--2020-01-03 20:42:16--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  12.4MB/s    in 54s     \n",
            "\n",
            "2020-01-03 20:43:11 (12.1 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXwLbmIPFSHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('glove.840B.300d.zip', 'r') as zf:\n",
        "    zf.extractall()\n",
        "\n",
        "with ZipFile('wiki-news-300d-1M.vec.zip', 'r') as zf:\n",
        "    zf.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlIUI2UDFXU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "d6b38aa1-3ed7-40fb-8615-9cea0246feaa"
      },
      "source": [
        "!wget https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip\n",
        "\n",
        "!mkdir data\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"OLIDv1.0.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"data\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-03 20:48:37--  https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip\n",
            "Resolving sites.google.com (sites.google.com)... 74.125.203.102, 74.125.203.100, 74.125.203.101, ...\n",
            "Connecting to sites.google.com (sites.google.com)|74.125.203.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attredirects=0 [following]\n",
            "--2020-01-03 20:48:37--  https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attredirects=0\n",
            "Reusing existing connection to sites.google.com:443.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://ef80a887-a-62cb3a1a-s-sites.googlegroups.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attachauth=ANoY7cqoTXIFVXVCLWjqamzh2WVHrW5s4qLQFyAA3wZlNYk_ntHIS7cScJRqELqIO_N0i4axWKdNXXX-RH5yXx6xiZ8HczEAsvs3zF-CPXHDRcky9EPulfUJpaU9SPD8hr0MJ2zH8SPbGT55Sji_d69jeNXsVaeA1sxtz_dkU8sN6oEycCiOlnuG4EKng9NggkA-O60a_r0JqDd1Hxwl7If_plGTPIRVyU4cdJ6g1_kY_S-yg2hZrN8%3D&attredirects=0 [following]\n",
            "--2020-01-03 20:48:37--  https://ef80a887-a-62cb3a1a-s-sites.googlegroups.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attachauth=ANoY7cqoTXIFVXVCLWjqamzh2WVHrW5s4qLQFyAA3wZlNYk_ntHIS7cScJRqELqIO_N0i4axWKdNXXX-RH5yXx6xiZ8HczEAsvs3zF-CPXHDRcky9EPulfUJpaU9SPD8hr0MJ2zH8SPbGT55Sji_d69jeNXsVaeA1sxtz_dkU8sN6oEycCiOlnuG4EKng9NggkA-O60a_r0JqDd1Hxwl7If_plGTPIRVyU4cdJ6g1_kY_S-yg2hZrN8%3D&attredirects=0\n",
            "Resolving ef80a887-a-62cb3a1a-s-sites.googlegroups.com (ef80a887-a-62cb3a1a-s-sites.googlegroups.com)... 74.125.203.137, 2404:6800:4008:c03::89\n",
            "Connecting to ef80a887-a-62cb3a1a-s-sites.googlegroups.com (ef80a887-a-62cb3a1a-s-sites.googlegroups.com)|74.125.203.137|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 874644 (854K) [application/zip]\n",
            "Saving to: ‘OLIDv1.0.zip’\n",
            "\n",
            "OLIDv1.0.zip        100%[===================>] 854.14K   718KB/s    in 1.2s    \n",
            "\n",
            "2020-01-03 20:48:38 (718 KB/s) - ‘OLIDv1.0.zip’ saved [874644/874644]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnOwTGAXpLvI",
        "colab_type": "code",
        "outputId": "53784932-3cfd-4c27-ec2c-50e3a9d1268a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import pandas as pd\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpYZxDnjpo32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv( 'data/olid-training-v1.0.tsv',sep=\"\\t\")\n",
        "test=pd.read_csv('data/testset-levela.tsv',sep=\"\\t\")\n",
        "y_test=pd.read_csv( 'data/labels-levela.csv',header=None).iloc[:,-1]\n",
        "#OFF=0 \n",
        "#NOT=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reTRftvWpUJk",
        "colab_type": "code",
        "outputId": "62d48abd-0960-442a-bc9d-e7c164834f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train=train['subtask_a']\n",
        "train=train['tweet']\n",
        "test=test['tweet']\n",
        "y_train=pd.factorize(y_train)[0]\n",
        "y_test=pd.factorize(y_test)[0]\n",
        "\n",
        "import collections\n",
        "collections.Counter(y_train)\n",
        "\n",
        "#Counter({0: 4400, 1: 8840})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 4400, 1: 8840})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KkTgzF_q4s1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the training corpus\n",
        "stop_words = set(stopwords.words(\"english\")) \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "corpus_train = []\n",
        "for i in train:\n",
        "    x=i.lower()\n",
        "    x=x.replace('@user','')\n",
        "    x=x.replace('@[\\w\\-]+','')\n",
        "    #x=x.translate(str.maketrans('', '', string.punctuation))\n",
        "    x = re.sub('[^A-Za-z]', ' ', x)\n",
        "    #x=re.sub('\\s+',' ',x)\n",
        "    x=re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
        "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',x) #url\n",
        "    #x = [lemmatizer.lemmatize(token) for token in x.split(\" \")]\n",
        "    #x = [word for word in x if not word in stop_words]\n",
        "    #x=\" \".join(x)\n",
        "    corpus_train.append(x)    \n",
        "# Creating the training corpus\n",
        "corpus_test = []\n",
        "for i in test:\n",
        "    x=i.lower()\n",
        "    x=x.replace('@user','')\n",
        "    x=x.replace('@[\\w\\-]+','')\n",
        "    #x=x.translate(str.maketrans('', '', string.punctuation))\n",
        "    x = re.sub('[^A-Za-z]', ' ', x)\n",
        "    #x=re.sub('\\s+',' ',x)\n",
        "    x=re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
        "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',x) #url\n",
        "    #x = [lemmatizer.lemmatize(token) for token in x.split(\" \")]\n",
        "    #x = [word for word in x if not word in stop_words]\n",
        "    #x=\" \".join(x)\n",
        "    corpus_test.append(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyyHvozBq7kf",
        "colab_type": "code",
        "outputId": "71f5a2ce-45b7-4209-e828-1a3c29b35c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 200\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(corpus_train)\n",
        "sequences = tokenize.texts_to_sequences(corpus_train)\n",
        "word_index = tokenize.word_index\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKtD5R2wIss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USp8rSPhwFoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a44cb932-2bff-472e-ea36-184afc4f1591"
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZhiwdYSwJQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_path1 = \"wiki-news-300d-1M.vec\"\n",
        "embedding_path2 = \"glove.840B.300d.txt\"\n",
        "embed_size = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3W_MgeVwJqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyxVJQ45rSW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def build_matrix(embedding_path, word_index):\n",
        "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "    nb_words = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words:\n",
        "            continue\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MicVGQWwMW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fasttext=build_matrix(embedding_path1, word_index)\n",
        "glove_emb=build_matrix(embedding_path2, word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGsonVx2wPf_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b88df0c2-85b7-42cf-e84e-03f1a8bae500"
      },
      "source": [
        "embedding_matrix=np.mean((fasttext,glove_emb),axis=0)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT0VJn4o8JHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.kaggle.com/buchan/transformer-network-with-1d-cnn-feature-extraction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ti71vuBrvhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random, os, sys\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.callbacks import *\n",
        "from keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from keras.engine.topology import Layer\n",
        "from sklearn.utils import class_weight\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "class ScaledDotProductAttention():\n",
        "    def __init__(self, d_model, attn_dropout=0.1):\n",
        "        self.temper = np.sqrt(d_model)\n",
        "        self.dropout = Dropout(attn_dropout)\n",
        "    def __call__(self, q, k, v, mask):\n",
        "        attn = Lambda(lambda x:K.batch_dot(x[0],x[1],axes=[2,2])/self.temper)([q, k])\n",
        "        if mask is not None:\n",
        "            mmask = Lambda(lambda x:(-1e+10)*(1-x))(mask)\n",
        "            attn = Add()([attn, mmask])\n",
        "        attn = Activation('softmax')(attn)\n",
        "        attn = self.dropout(attn)\n",
        "        output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v])\n",
        "        return output, attn\n",
        "\n",
        "class MultiHeadAttention():\n",
        "    # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
        "    def __init__(self, n_head, d_model, d_k, d_v, dropout, mode=0, use_norm=True):\n",
        "        self.mode = mode\n",
        "        self.n_head = n_head\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.dropout = dropout\n",
        "        if mode == 0:\n",
        "            self.qs_layer = Dense(n_head*d_k, use_bias=False)\n",
        "            self.ks_layer = Dense(n_head*d_k, use_bias=False)\n",
        "            self.vs_layer = Dense(n_head*d_v, use_bias=False)\n",
        "        elif mode == 1:\n",
        "            self.qs_layers = []\n",
        "            self.ks_layers = []\n",
        "            self.vs_layers = []\n",
        "            for _ in range(n_head):\n",
        "                self.qs_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
        "                self.ks_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
        "                self.vs_layers.append(TimeDistributed(Dense(d_v, use_bias=False)))\n",
        "        self.attention = ScaledDotProductAttention(d_model)\n",
        "        self.layer_norm = LayerNormalization() if use_norm else None\n",
        "        self.w_o = TimeDistributed(Dense(d_model))\n",
        "\n",
        "    def __call__(self, q, k, v, mask=None):\n",
        "        d_k, d_v = self.d_k, self.d_v\n",
        "        n_head = self.n_head\n",
        "\n",
        "        if self.mode == 0:\n",
        "            qs = self.qs_layer(q)  # [batch_size, len_q, n_head*d_k]\n",
        "            ks = self.ks_layer(k)\n",
        "            vs = self.vs_layer(v)\n",
        "\n",
        "            def reshape1(x):\n",
        "                s = tf.shape(x)   # [batch_size, len_q, n_head * d_k]\n",
        "                x = tf.reshape(x, [s[0], s[1], n_head, d_k])\n",
        "                x = tf.transpose(x, [2, 0, 1, 3])  \n",
        "                x = tf.reshape(x, [-1, s[1], d_k])  # [n_head * batch_size, len_q, d_k]\n",
        "                return x\n",
        "            qs = Lambda(reshape1)(qs)\n",
        "            ks = Lambda(reshape1)(ks)\n",
        "            vs = Lambda(reshape1)(vs)\n",
        "\n",
        "            if mask is not None:\n",
        "                mask = Lambda(lambda x:K.repeat_elements(x, n_head, 0))(mask)\n",
        "            head, attn = self.attention(qs, ks, vs, mask=mask)  \n",
        "                \n",
        "            def reshape2(x):\n",
        "                s = tf.shape(x)   # [n_head * batch_size, len_v, d_v]\n",
        "                x = tf.reshape(x, [n_head, -1, s[1], s[2]]) \n",
        "                x = tf.transpose(x, [1, 2, 0, 3])\n",
        "                x = tf.reshape(x, [-1, s[1], n_head*d_v])  # [batch_size, len_v, n_head * d_v]\n",
        "                return x\n",
        "            head = Lambda(reshape2)(head)\n",
        "        elif self.mode == 1:\n",
        "            heads = []; attns = []\n",
        "            for i in range(n_head):\n",
        "                qs = self.qs_layers[i](q)   \n",
        "                ks = self.ks_layers[i](k) \n",
        "                vs = self.vs_layers[i](v) \n",
        "                head, attn = self.attention(qs, ks, vs, mask)\n",
        "                heads.append(head); attns.append(attn)\n",
        "            head = Concatenate()(heads) if n_head > 1 else heads[0]\n",
        "            attn = Concatenate()(attns) if n_head > 1 else attns[0]\n",
        "\n",
        "        outputs = self.w_o(head)\n",
        "        outputs = Dropout(self.dropout)(outputs)\n",
        "        if not self.layer_norm: return outputs, attn\n",
        "        # outputs = Add()([outputs, q]) # sl: fix\n",
        "        return self.layer_norm(outputs), attn\n",
        "\n",
        "class PositionwiseFeedForward():\n",
        "    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
        "        self.w_1 = Conv1D(d_inner_hid, 1, activation='relu')\n",
        "        self.w_2 = Conv1D(d_hid, 1)\n",
        "        self.layer_norm = LayerNormalization()\n",
        "        self.dropout = Dropout(dropout)\n",
        "    def __call__(self, x):\n",
        "        output = self.w_1(x) \n",
        "        output = self.w_2(output)\n",
        "        output = self.dropout(output)\n",
        "        output = Add()([output, x])\n",
        "        return self.layer_norm(output)\n",
        "\n",
        "class EncoderLayer():\n",
        "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
        "        self.self_att_layer = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
        "        self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
        "    def __call__(self, enc_input, mask=None):\n",
        "        output, slf_attn = self.self_att_layer(enc_input, enc_input, enc_input, mask=mask)\n",
        "        output = self.pos_ffn_layer(output)\n",
        "        return output, slf_attn\n",
        "\n",
        "\n",
        "def GetPosEncodingMatrix(max_len, d_emb):\n",
        "    pos_enc = np.array([\n",
        "        [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] \n",
        "        if pos != 0 else np.zeros(d_emb) \n",
        "            for pos in range(max_len)\n",
        "            ])\n",
        "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
        "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
        "    return pos_enc\n",
        "\n",
        "def GetPadMask(q, k):\n",
        "    ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
        "    mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
        "    mask = K.batch_dot(ones, mask, axes=[2,1])\n",
        "    return mask\n",
        "\n",
        "def GetSubMask(s):\n",
        "    len_s = tf.shape(s)[1]\n",
        "    bs = tf.shape(s)[:1]\n",
        "    mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzopG0hswgUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sequences = tokenize.texts_to_sequences(corpus_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL7IqfKhwk8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    '''\n",
        "    metric from here \n",
        "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
        "    '''\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsj6_9rzwn3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "class EarlyStoppingByAccuracy(Callback):\n",
        "    def __init__(self, monitor='val_loss', value=0.39, verbose=0):\n",
        "        super(Callback, self).__init__()\n",
        "        self.monitor = monitor\n",
        "        self.value = value\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
        "\n",
        "        if current >= self.value:\n",
        "            if self.verbose > 0:\n",
        "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
        "            self.model.stop_training = True\n",
        "callbacks = EarlyStoppingByAccuracy(monitor='val_f1', value=0.89, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41kBO5_m0k_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "inp = Input(shape=(None, ))\n",
        "#x = Embedding(max_features, embed_size, weights=[embedding_matrix])(src_seq_input)\n",
        "x=Embedding(num_words,embed_size,embeddings_initializer=Constant(embedding_matrix),input_length=max_len,trainable=False)(inp)\n",
        "#x = Conv1D(32, kernel_size = 5, strides = 2, activation='relu')(x)\n",
        "#x = Conv1D(64, kernel_size = 5, strides = 2, activation='relu')(x)\n",
        "\n",
        "x = SpatialDropout1D(0.2)(x)\n",
        "x=Bidirectional(CuDNNGRU(100, return_sequences = True))(x)\n",
        "\n",
        "x, slf_attn = MultiHeadAttention(n_head=2, d_model=200, d_k=64, d_v=64, dropout=0.1)(x, x, x)\n",
        "\n",
        "avg_pool = GlobalAveragePooling1D()(x)\n",
        "max_pool = GlobalMaxPooling1D()(x)\n",
        "conc = concatenate([avg_pool, max_pool])\n",
        "fc = Dense(64, activation=\"relu\")(conc)\n",
        "fc = Dense(32, activation=\"relu\")(fc)\n",
        "out = Dense(1, activation=\"sigmoid\")(fc)   \n",
        "\n",
        "\n",
        "model = Model(inputs=inp, outputs=out)\n",
        "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=[f1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2bvLdwF6cvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_f1', factor=0.2,\n",
        "                              patience=2, min_lr=0.000001, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf6pnXqk47a7",
        "colab_type": "code",
        "outputId": "70886d3b-7489-4227-ddd3-295e6e689582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        }
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "class_weights=dict(enumerate(class_weights))\n",
        "model.fit(sequences_matrix,y_train,batch_size=512,epochs=20,verbose=2,class_weight=class_weights,\n",
        "          validation_data=(test_sequences_matrix,y_test),callbacks=[callbacks,reduce_lr])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13240 samples, validate on 860 samples\n",
            "Epoch 1/20\n",
            " - 18s - loss: 0.7481 - f1: 0.5063 - val_loss: 0.6446 - val_f1: 0.8390\n",
            "Epoch 2/20\n",
            " - 4s - loss: 0.6577 - f1: 0.6609 - val_loss: 0.4666 - val_f1: 0.8621\n",
            "Epoch 3/20\n",
            " - 4s - loss: 0.5189 - f1: 0.8066 - val_loss: 0.4109 - val_f1: 0.8760\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 4/20\n",
            " - 4s - loss: 0.4966 - f1: 0.8133 - val_loss: 0.4057 - val_f1: 0.8708\n",
            "Epoch 5/20\n",
            " - 4s - loss: 0.4897 - f1: 0.8156 - val_loss: 0.4008 - val_f1: 0.8743\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 6/20\n",
            " - 4s - loss: 0.4900 - f1: 0.8160 - val_loss: 0.3976 - val_f1: 0.8797\n",
            "Epoch 7/20\n",
            " - 4s - loss: 0.4863 - f1: 0.8165 - val_loss: 0.3993 - val_f1: 0.8766\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "Epoch 8/20\n",
            " - 4s - loss: 0.4877 - f1: 0.8136 - val_loss: 0.3971 - val_f1: 0.8790\n",
            "Epoch 9/20\n",
            " - 4s - loss: 0.4842 - f1: 0.8126 - val_loss: 0.3957 - val_f1: 0.8801\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
            "Epoch 10/20\n",
            " - 4s - loss: 0.4860 - f1: 0.8159 - val_loss: 0.3958 - val_f1: 0.8801\n",
            "Epoch 11/20\n",
            " - 4s - loss: 0.4827 - f1: 0.8171 - val_loss: 0.3959 - val_f1: 0.8808\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "Epoch 12/20\n",
            " - 4s - loss: 0.4827 - f1: 0.8179 - val_loss: 0.3959 - val_f1: 0.8799\n",
            "Epoch 13/20\n",
            " - 4s - loss: 0.4870 - f1: 0.8142 - val_loss: 0.3960 - val_f1: 0.8799\n",
            "Epoch 14/20\n",
            " - 4s - loss: 0.4849 - f1: 0.8178 - val_loss: 0.3959 - val_f1: 0.8799\n",
            "Epoch 15/20\n",
            " - 4s - loss: 0.4856 - f1: 0.8143 - val_loss: 0.3960 - val_f1: 0.8799\n",
            "Epoch 16/20\n",
            " - 4s - loss: 0.4862 - f1: 0.8165 - val_loss: 0.3960 - val_f1: 0.8799\n",
            "Epoch 17/20\n",
            " - 4s - loss: 0.4852 - f1: 0.8152 - val_loss: 0.3960 - val_f1: 0.8799\n",
            "Epoch 18/20\n",
            " - 4s - loss: 0.4869 - f1: 0.8153 - val_loss: 0.3960 - val_f1: 0.8799\n",
            "Epoch 19/20\n",
            " - 4s - loss: 0.4869 - f1: 0.8141 - val_loss: 0.3960 - val_f1: 0.8799\n",
            "Epoch 20/20\n",
            " - 4s - loss: 0.4848 - f1: 0.8153 - val_loss: 0.3960 - val_f1: 0.8799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70a41a4cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BD-ntr8rznW",
        "colab_type": "code",
        "outputId": "b6787bfd-daba-4963-e307-460b7ffa2076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_sequences = tokenize.texts_to_sequences(corpus_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
        "print(model.evaluate(test_sequences_matrix,y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "860/860 [==============================] - 0s 260us/step\n",
            "[0.396033970422523, 0.8774362297945244]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-fKEe-4rzp4",
        "colab_type": "code",
        "outputId": "6181f538-3520-4adc-e7e8-0c8cedd30809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(test_sequences_matrix, batch_size=128, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "860/860 [==============================] - 0s 307us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.72      0.70       240\n",
            "           1       0.89      0.87      0.88       620\n",
            "\n",
            "    accuracy                           0.83       860\n",
            "   macro avg       0.79      0.80      0.79       860\n",
            "weighted avg       0.83      0.83      0.83       860\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72QjwwRRrzsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o9xT3kjyc7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}