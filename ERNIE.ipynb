{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ERNIE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/Offensive-Language-Detection/blob/master/ERNIE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRaPCuG8W_1m",
        "colab_type": "code",
        "outputId": "268abca5-0e66-4e2b-be7b-63a1daf7a08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install paddlepaddle-gpu\n",
        "!wget https://ernie.bj.bcebos.com/ERNIE_Base_en_stable-2.0.0.tar.gz\n",
        "!gunzip ERNIE_Base_en_stable-2.0.0.tar.gz\n",
        "!tar -xvf ERNIE_Base_en_stable-2.0.0.tar\n",
        "!git clone https://github.com/PaddlePaddle/ERNIE.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting paddlepaddle-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/48/19898a6fa6f4d8d6de9c13de80c5e4fa7f84b5f20dfc16c93801e339078a/paddlepaddle_gpu-1.5.1.post107-cp36-cp36m-manylinux1_x86_64.whl (236.1MB)\n",
            "\u001b[K     |████████████████████████████████| 236.1MB 129kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (2.21.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.2.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.0.3)\n",
            "Collecting rarfile (from paddlepaddle-gpu)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/a4/8b4abc72310da6fa53b6de8de1019e0516885d05369d6c91cba23476abe5/rarfile-3.0.tar.gz (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.13)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (1.16.4)\n",
            "Collecting funcsigs (from paddlepaddle-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.4.5.20)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (4.3.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (0.10.1)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.7.1)\n",
            "Collecting recordio>=0.1.0 (from paddlepaddle-gpu)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/30/14a03c04164c706a5b9c0bf5249a0599c87911c144cf78e9e9615abade43/recordio-0.1.7-cp36-cp36m-manylinux1_x86_64.whl (897kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2019.6.16)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->paddlepaddle-gpu) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->paddlepaddle-gpu) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->paddlepaddle-gpu) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->paddlepaddle-gpu) (2.4.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->paddlepaddle-gpu) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->paddlepaddle-gpu) (41.0.1)\n",
            "Building wheels for collected packages: rarfile\n",
            "  Building wheel for rarfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rarfile: filename=rarfile-3.0-cp36-none-any.whl size=24207 sha256=b4771d1a102473f0d26430f14f61bbc79cd22893a94177e473adc1faac5352c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/84/da/8aff50941f548db5384b076d5a6a6afea0cd12672e0326edc4\n",
            "Successfully built rarfile\n",
            "\u001b[31mERROR: paddlepaddle-gpu 1.5.1.post107 has requirement matplotlib<=2.2.4, but you'll have matplotlib 3.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: paddlepaddle-gpu 1.5.1.post107 has requirement scipy<=1.2.1,>=0.19.0, but you'll have scipy 1.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: rarfile, funcsigs, recordio, paddlepaddle-gpu\n",
            "Successfully installed funcsigs-1.0.2 paddlepaddle-gpu-1.5.1.post107 rarfile-3.0 recordio-0.1.7\n",
            "--2019-08-07 07:23:57--  https://ernie.bj.bcebos.com/ERNIE_Base_en_stable-2.0.0.tar.gz\n",
            "Resolving ernie.bj.bcebos.com (ernie.bj.bcebos.com)... 39.156.69.23, 111.206.47.194, 112.34.112.29, ...\n",
            "Connecting to ernie.bj.bcebos.com (ernie.bj.bcebos.com)|39.156.69.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405413980 (387M) [application/x-gzip]\n",
            "Saving to: ‘ERNIE_Base_en_stable-2.0.0.tar.gz’\n",
            "\n",
            "ERNIE_Base_en_stabl 100%[===================>] 386.63M  12.4MB/s    in 58s     \n",
            "\n",
            "2019-08-07 07:24:57 (6.67 MB/s) - ‘ERNIE_Base_en_stable-2.0.0.tar.gz’ saved [405413980/405413980]\n",
            "\n",
            "ernie_config.json\n",
            "params/\n",
            "params/encoder_layer_4_post_att_layer_norm_scale\n",
            "params/encoder_layer_2_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_2_ffn_fc_1.w_0\n",
            "params/encoder_layer_6_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_7_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_11_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_5_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_1_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_11_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_7_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_1_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_9_ffn_fc_1.b_0\n",
            "params/encoder_layer_4_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_2_ffn_fc_1.b_0\n",
            "params/encoder_layer_7_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_7_post_att_layer_norm_scale\n",
            "params/encoder_layer_6_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_3_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_1_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_10_ffn_fc_0.w_0\n",
            "params/encoder_layer_6_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_3_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_8_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_4_post_att_layer_norm_bias\n",
            "params/pre_encoder_layer_norm_scale\n",
            "params/encoder_layer_2_post_att_layer_norm_scale\n",
            "params/encoder_layer_5_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_ffn_fc_0.b_0\n",
            "params/encoder_layer_4_ffn_fc_1.b_0\n",
            "params/encoder_layer_10_ffn_fc_1.w_0\n",
            "params/encoder_layer_2_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_3_post_att_layer_norm_bias\n",
            "params/encoder_layer_1_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_0_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_8_ffn_fc_1.b_0\n",
            "params/encoder_layer_3_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_2_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_6_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_6_post_att_layer_norm_scale\n",
            "params/encoder_layer_0_post_att_layer_norm_scale\n",
            "params/encoder_layer_2_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_5_ffn_fc_1.w_0\n",
            "params/encoder_layer_0_ffn_fc_0.b_0\n",
            "params/encoder_layer_1_post_att_layer_norm_scale\n",
            "params/encoder_layer_6_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_5_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_11_post_att_layer_norm_scale\n",
            "params/encoder_layer_9_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_9_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_0_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_2_ffn_fc_0.w_0\n",
            "params/pos_embedding\n",
            "params/encoder_layer_8_ffn_fc_0.b_0\n",
            "params/encoder_layer_11_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_0_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_9_post_att_layer_norm_bias\n",
            "params/encoder_layer_2_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_9_multi_head_att_key_fc.b_0\n",
            "params/task_embedding\n",
            "params/encoder_layer_10_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_4_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_0_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_10_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_1_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_5_post_att_layer_norm_scale\n",
            "params/encoder_layer_8_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_0_ffn_fc_0.w_0\n",
            "params/encoder_layer_5_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_7_ffn_fc_0.w_0\n",
            "params/encoder_layer_7_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_7_ffn_fc_1.w_0\n",
            "params/encoder_layer_2_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_9_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_9_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_9_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_4_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_11_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_1_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_0_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_6_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_7_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_8_ffn_fc_1.w_0\n",
            "params/encoder_layer_9_ffn_fc_1.w_0\n",
            "params/sent_embedding\n",
            "params/encoder_layer_0_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_6_ffn_fc_0.w_0\n",
            "params/encoder_layer_1_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_6_ffn_fc_1.b_0\n",
            "params/encoder_layer_0_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_2_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_0_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_9_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_1_ffn_fc_1.w_0\n",
            "params/encoder_layer_0_ffn_fc_1.w_0\n",
            "params/encoder_layer_8_ffn_fc_0.w_0\n",
            "params/encoder_layer_11_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_5_ffn_fc_0.w_0\n",
            "params/pre_encoder_layer_norm_bias\n",
            "params/encoder_layer_6_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_10_ffn_fc_0.b_0\n",
            "params/encoder_layer_6_ffn_fc_1.w_0\n",
            "params/encoder_layer_4_ffn_fc_1.w_0\n",
            "params/encoder_layer_2_ffn_fc_0.b_0\n",
            "params/encoder_layer_5_ffn_fc_0.b_0\n",
            "params/encoder_layer_10_ffn_fc_1.b_0\n",
            "params/pooled_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_8_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_3_ffn_fc_0.b_0\n",
            "params/encoder_layer_11_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_9_ffn_fc_0.w_0\n",
            "params/encoder_layer_9_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_0_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_7_post_att_layer_norm_bias\n",
            "params/encoder_layer_3_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_11_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_5_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_0_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_4_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_3_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_3_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_11_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_8_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_4_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_6_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_9_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_3_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_6_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_9_ffn_fc_0.b_0\n",
            "params/encoder_layer_10_post_att_layer_norm_scale\n",
            "params/encoder_layer_11_ffn_fc_0.b_0\n",
            "params/pooled_fc.b_0\n",
            "params/encoder_layer_2_post_att_layer_norm_bias\n",
            "params/encoder_layer_8_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_1_ffn_fc_0.w_0\n",
            "params/encoder_layer_4_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_8_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_10_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_6_ffn_fc_0.b_0\n",
            "params/encoder_layer_5_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_3_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_3_ffn_fc_1.b_0\n",
            "params/encoder_layer_10_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_10_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_8_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_8_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_11_post_att_layer_norm_bias\n",
            "params/encoder_layer_8_post_att_layer_norm_scale\n",
            "params/encoder_layer_10_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_ffn_fc_0.w_0\n",
            "params/encoder_layer_1_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_4_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_11_ffn_fc_0.w_0\n",
            "params/encoder_layer_3_post_att_layer_norm_scale\n",
            "params/encoder_layer_10_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_11_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_6_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_8_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_0_ffn_fc_1.b_0\n",
            "params/encoder_layer_9_post_att_layer_norm_scale\n",
            "params/word_embedding\n",
            "params/encoder_layer_3_ffn_fc_1.w_0\n",
            "params/encoder_layer_11_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_3_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_11_ffn_fc_1.b_0\n",
            "params/encoder_layer_2_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_3_ffn_fc_0.w_0\n",
            "params/encoder_layer_5_ffn_fc_1.b_0\n",
            "params/encoder_layer_1_ffn_fc_0.b_0\n",
            "params/encoder_layer_1_ffn_fc_1.b_0\n",
            "params/encoder_layer_8_post_att_layer_norm_bias\n",
            "params/encoder_layer_7_ffn_fc_0.b_0\n",
            "params/encoder_layer_1_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_2_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_7_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_3_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_11_ffn_fc_1.w_0\n",
            "params/encoder_layer_1_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_0_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_2_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_4_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_8_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_7_ffn_fc_1.b_0\n",
            "params/encoder_layer_1_post_att_layer_norm_bias\n",
            "params/encoder_layer_9_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_6_post_ffn_layer_norm_bias\n",
            "vocab.txt\n",
            "Cloning into 'ERNIE'...\n",
            "remote: Enumerating objects: 2, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 873 (delta 0), reused 0 (delta 0), pack-reused 871\u001b[K\n",
            "Receiving objects: 100% (873/873), 15.07 MiB | 28.22 MiB/s, done.\n",
            "Resolving deltas: 100% (493/493), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_1rIRFGZXUi",
        "colab_type": "text"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GLnT6rmZWcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiD_pnTGX3H1",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6rCMa1fZB2u",
        "colab_type": "code",
        "outputId": "312493bb-7c57-46ab-f644-1ab2c07d1f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!wget !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
        "!unzip 'drugsCom_raw.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-07 07:25:30--  http://!wget/\n",
            "Resolving !wget (!wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘!wget’\n",
            "--2019-08-07 07:25:30--  https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42989872 (41M) [application/x-httpd-php]\n",
            "Saving to: ‘drugsCom_raw.zip’\n",
            "\n",
            "drugsCom_raw.zip    100%[===================>]  41.00M  49.0MB/s    in 0.8s    \n",
            "\n",
            "2019-08-07 07:25:31 (49.0 MB/s) - ‘drugsCom_raw.zip’ saved [42989872/42989872]\n",
            "\n",
            "FINISHED --2019-08-07 07:25:31--\n",
            "Total wall clock time: 1.1s\n",
            "Downloaded: 1 files, 41M in 0.8s (49.0 MB/s)\n",
            "Archive:  drugsCom_raw.zip\n",
            "  inflating: drugsComTest_raw.tsv    \n",
            "  inflating: drugsComTrain_raw.tsv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnwspcURZQq6",
        "colab_type": "code",
        "outputId": "b1e8eb26-cda6-49bb-e95c-90a29372a076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "df = pd.read_csv('drugsComTrain_raw.tsv', delimiter='\\t')\n",
        "df = df[['review', 'rating']]\n",
        "df.columns = ['text_a', 'label']\n",
        "df['label'] = df['label'].apply(lambda x: int(x))\n",
        "df['label'] = df['label'].apply(lambda x: 1 if int(x) > 5 else 0)\n",
        "df['text_a'] = df['text_a'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', str(x)))\n",
        "df = df.head(2000)\n",
        "!mkdir -p 'dataset/SST-2'\n",
        "train = df.loc[:int(len(df)*0.8),:]\n",
        "dev = df.loc[int(len(df)*0.8):int(len(df)*0.9),:]\n",
        "test = df.loc[int(len(df)*0.9):,:]\n",
        "print(len(train), len(dev), len(test))\n",
        "train.to_csv('train.tsv', index=False, sep='\\t')\n",
        "dev.to_csv('dev.tsv', index=False, sep='\\t')\n",
        "test.to_csv('test.tsv', index=False, sep='\\t')\n",
        "print(\"saved\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1601 201 200\n",
            "saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv-bhT97brgE",
        "colab_type": "text"
      },
      "source": [
        "## Get environment ready for train and testing\n",
        "\n",
        "### -create new folder for dataset\n",
        "### -set path for model parameters and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdYqqG4_bq5D",
        "colab_type": "code",
        "outputId": "515bcf77-56bd-40f7-9d4d-c60fd7c37dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir -p parameters/params\n",
        "!mv train.tsv dataset/SST-2/\n",
        "!mv dev.tsv dataset/SST-2/\n",
        "!mv test.tsv dataset/SST-2/\n",
        "!mv params/ parameters/params"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'params/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bQdjv7Ce_dZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv dataset/ ERNIE/\n",
        "!mv parameters/ ERNIE/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0XGR5piSx-f",
        "colab_type": "text"
      },
      "source": [
        "## Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPHtxNo9Zjnh",
        "colab_type": "code",
        "outputId": "3b7e36ea-e628-4e85-fe39-05f34842c1ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir('ERNIE/')\n",
        "os.environ['TASK_DATA_PATH']='dataset'\n",
        "os.environ['MODEL_PATH']='parameters/params'\n",
        "print(os.getcwd())\n",
        "!sh script/en_glue/ernie_base/SST-2/task.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ERNIE\n",
            "script/en_glue/ernie_base/SST-2/task.sh: 7: script/en_glue/ernie_base/SST-2/task.sh: [[: not found\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 32\n",
            "checkpoints: ./checkpoints\n",
            "dev_set: dataset/SST-2/dev.tsv\n",
            "diagnostic: None\n",
            "diagnostic_save: None\n",
            "do_lower_case: True\n",
            "do_test: True\n",
            "do_train: True\n",
            "do_val: True\n",
            "doc_stride: 128\n",
            "enable_ce: False\n",
            "epoch: 4\n",
            "ernie_config_path: script/en_glue/ernie_base/ernie_config.json\n",
            "for_cn: False\n",
            "in_tokens: False\n",
            "init_checkpoint: None\n",
            "init_pretraining_params: parameters/params/params\n",
            "is_classify: True\n",
            "is_regression: False\n",
            "label_map_config: None\n",
            "learning_rate: 2e-05\n",
            "loss_scaling: 1.0\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_answer_length: 100\n",
            "max_query_length: 64\n",
            "max_seq_len: 128\n",
            "metric: simple_accuracy\n",
            "metrics: True\n",
            "n_best_size: 20\n",
            "num_iteration_per_drop_scope: 1\n",
            "num_labels: 2\n",
            "predict_batch_size: None\n",
            "random_seed: 1\n",
            "save_steps: 10000\n",
            "shuffle: True\n",
            "skip_steps: 10\n",
            "task_id: 0\n",
            "test_save: output/test_out.{1..5}.2e-5.32.4.tsv\n",
            "test_set: dataset/SST-2/test.tsv\n",
            "tokenizer: FullTokenizer\n",
            "train_set: dataset/SST-2/train.tsv\n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fp16: False\n",
            "use_multi_gpu_test: False\n",
            "validation_steps: 800000000000\n",
            "verbose: True\n",
            "vocab_path: script/en_glue/ernie_base/vocab.txt\n",
            "warmup_proportion: 0.1\n",
            "weight_decay: 0.0\n",
            "------------------------------------------------\n",
            "attention_probs_dropout_prob: 0.1\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "task_type_vocab_size: 16\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "Device count: 1\n",
            "Num train examples: 1601\n",
            "Max train steps: 200\n",
            "Num warmup steps: 20\n",
            "Theoretical memory usage in training: 17039.885 - 17851.308 MB\n",
            "W0807 07:28:49.190436   255 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.0, Runtime API Version: 10.0\n",
            "W0807 07:28:49.541750   255 device_context.cc:267] device: 0, cuDNN Version: 7.6.\n",
            "Load pretraining parameters from parameters/params/params.\n",
            "WARNING:root:\n",
            "     You can try our memory optimize feature to save your memory usage:\n",
            "         # create a build_strategy variable to set memory optimize option\n",
            "         build_strategy = compiler.BuildStrategy()\n",
            "         build_strategy.enable_inplace = True\n",
            "         build_strategy.memory_optimize = True\n",
            "         \n",
            "         # pass the build_strategy to with_data_parallel API\n",
            "         compiled_prog = compiler.CompiledProgram(main).with_data_parallel(\n",
            "             loss_name=loss.name, build_strategy=build_strategy)\n",
            "      \n",
            "     !!! Memory optimize is our experimental feature !!!\n",
            "         some variables may be removed/reused internal to save memory usage, \n",
            "         in order to fetch the right value of the fetch_list, please set the \n",
            "         persistable property to true for each variable in fetch_list\n",
            "\n",
            "         # Sample\n",
            "         conv1 = fluid.layers.conv2d(data, 4, 5, 1, act=None) \n",
            "         # if you need to fetch conv1, then:\n",
            "         conv1.persistable = True\n",
            "\n",
            "                 \n",
            "I0807 07:28:49.938736   255 parallel_executor.cc:329] The number of CUDAPlace, which is used in ParallelExecutor, is 1. And the Program will be copied 1 copies\n",
            "I0807 07:28:49.991509   255 build_strategy.cc:340] SeqOnlyAllReduceOps:0, num_trainers:1\n",
            "train pyreader queue size: 50, learning rate: 0.000009\n",
            "epoch: 1, progress: 352/1601, step: 10, ave loss: 0.565993, ave acc: 0.750000, speed: 1.209770 steps/s\n",
            "validation result of dataset dataset/SST-2/dev.tsv:\n",
            "[dev evaluation] ave loss: 0.682082, acc:0.656716, data_num: 201, elapsed time: 1.866514 s, file: dataset/SST-2/dev.tsv, epoch: 1, steps: 10\n",
            "testing dataset/SST-2/test.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.1.10\n",
            "train pyreader queue size: 50, learning rate: 0.000019\n",
            "epoch: 1, progress: 672/1601, step: 20, ave loss: 0.378845, ave acc: 0.875000, speed: 0.835583 steps/s\n",
            "train pyreader queue size: 50, learning rate: 0.000017\n",
            "epoch: 1, progress: 992/1601, step: 30, ave loss: 0.372116, ave acc: 0.875000, speed: 1.186801 steps/s\n",
            "train pyreader queue size: 50, learning rate: 0.000016\n",
            "epoch: 1, progress: 1312/1601, step: 40, ave loss: 0.404077, ave acc: 0.875000, speed: 1.164198 steps/s\n",
            "train pyreader queue size: 50, learning rate: 0.000015\n",
            "epoch: 1, progress: 1600/1601, step: 50, ave loss: 0.495947, ave acc: 0.812500, speed: 1.135599 steps/s\n",
            "train pyreader queue size: 50, learning rate: 0.000014\n",
            "epoch: 2, progress: 320/1601, step: 60, ave loss: 0.274718, ave acc: 0.875000, speed: 1.228756 steps/s\n",
            "validation result of dataset dataset/SST-2/dev.tsv:\n",
            "[dev evaluation] ave loss: 0.411577, acc:0.830846, data_num: 201, elapsed time: 2.028395 s, file: dataset/SST-2/dev.tsv, epoch: 2, steps: 60\n",
            "testing dataset/SST-2/test.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.2.60\n",
            "train pyreader queue size: 50, learning rate: 0.000013\n",
            "epoch: 2, progress: 640/1601, step: 70, ave loss: 0.370858, ave acc: 0.875000, speed: 0.765961 steps/s\n",
            "train pyreader queue size: 50, learning rate: 0.000012\n",
            "epoch: 2, progress: 960/1601, step: 80, ave loss: 0.208480, ave acc: 0.937500, speed: 1.073704 steps/s\n",
            "train pyreader queue size: 50, learning rate: 0.000011\n",
            "epoch: 2, progress: 1280/1601, step: 90, ave loss: 0.170477, ave acc: 0.937500, speed: 1.034938 steps/s\n",
            "train pyreader queue size: 50, learning rate: 0.000010\n",
            "epoch: 2, progress: 1600/1601, step: 100, ave loss: 0.171698, ave acc: 0.906250, speed: 1.013588 steps/s\n",
            "train pyreader queue size: 50, learning rate: 0.000009\n",
            "epoch: 3, progress: 288/1601, step: 110, ave loss: 0.149100, ave acc: 0.937500, speed: 1.138790 steps/s\n",
            "validation result of dataset dataset/SST-2/dev.tsv:\n",
            "[dev evaluation] ave loss: 0.338611, acc:0.855721, data_num: 201, elapsed time: 2.052277 s, file: dataset/SST-2/dev.tsv, epoch: 3, steps: 110\n",
            "testing dataset/SST-2/test.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.3.110\n",
            "train pyreader queue size: 50, learning rate: 0.000008\n",
            "epoch: 3, progress: 608/1601, step: 120, ave loss: 0.155526, ave acc: 0.937500, speed: 0.743085 steps/s\n",
            "train pyreader queue size: 50, learning rate: 0.000007\n",
            "epoch: 3, progress: 928/1601, step: 130, ave loss: 0.152476, ave acc: 0.968750, speed: 1.079288 steps/s\n",
            "train pyreader queue size: 50, learning rate: 0.000006\n",
            "epoch: 3, progress: 1248/1601, step: 140, ave loss: 0.102654, ave acc: 0.968750, speed: 1.087752 steps/s\n",
            "train pyreader queue size: 50, learning rate: 0.000005\n",
            "epoch: 3, progress: 1568/1601, step: 150, ave loss: 0.228082, ave acc: 0.937500, speed: 1.090529 steps/s\n",
            "train pyreader queue size: 43, learning rate: 0.000004\n",
            "epoch: 3, progress: 1600/1601, step: 160, ave loss: 0.024265, ave acc: 1.000000, speed: 1.192722 steps/s\n",
            "train pyreader queue size: 33, learning rate: 0.000003\n",
            "epoch: 3, progress: 1600/1601, step: 170, ave loss: 0.036434, ave acc: 1.000000, speed: 1.072566 steps/s\n",
            "train pyreader queue size: 23, learning rate: 0.000002\n",
            "epoch: 3, progress: 1600/1601, step: 180, ave loss: 0.046030, ave acc: 1.000000, speed: 1.066602 steps/s\n",
            "train pyreader queue size: 13, learning rate: 0.000001\n",
            "epoch: 3, progress: 1600/1601, step: 190, ave loss: 0.039527, ave acc: 1.000000, speed: 1.061956 steps/s\n",
            "train pyreader queue size: 3, learning rate: 0.000000\n",
            "epoch: 3, progress: 1600/1601, step: 200, ave loss: 0.018993, ave acc: 1.000000, speed: 1.060893 steps/s\n",
            "validation result of dataset dataset/SST-2/dev.tsv:\n",
            "[dev evaluation] ave loss: 0.421852, acc:0.875622, data_num: 201, elapsed time: 2.105736 s, file: dataset/SST-2/dev.tsv, epoch: 3, steps: 205\n",
            "testing dataset/SST-2/test.tsv, save to output/test_out.{1..5}.2e-5.32.4.tsv.3.205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azjtwZKIkjBl",
        "colab_type": "code",
        "outputId": "9e630348-8bfa-4168-de11-c6784900106f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!python3 predict_classifier.py -u --ernie_config_path script/en_glue/ernie_base/ernie_config.json --init_check_point checkpoints/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: Load classifier's checkpoint to do prediction or save inference model.\n",
            "       [-h] [--ernie_config_path ERNIE_CONFIG_PATH]\n",
            "       [--init_checkpoint INIT_CHECKPOINT]\n",
            "       [--save_inference_model_path SAVE_INFERENCE_MODEL_PATH]\n",
            "       [--use_fp16 USE_FP16] [--num_labels NUM_LABELS]\n",
            "       [--ernie_version ERNIE_VERSION] [--predict_set PREDICT_SET]\n",
            "       [--vocab_path VOCAB_PATH] [--label_map_config LABEL_MAP_CONFIG]\n",
            "       [--max_seq_len MAX_SEQ_LEN] [--batch_size BATCH_SIZE]\n",
            "       [--do_lower_case DO_LOWER_CASE] [--use_cuda USE_CUDA]\n",
            "       [--do_prediction DO_PREDICTION]\n",
            "Load classifier's checkpoint to do prediction or save inference model.: error: unrecognized arguments: -u --init_check_point checkpoints/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg1-k9RIH83C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}