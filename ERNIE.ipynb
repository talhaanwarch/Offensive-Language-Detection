{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ERNIE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/Offensive-Language-Detection/blob/master/ERNIE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRaPCuG8W_1m",
        "colab_type": "code",
        "outputId": "6024e154-2543-424e-bd1b-ac3032d96460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install paddlepaddle-gpu\n",
        "!wget https://ernie.bj.bcebos.com/ERNIE_Base_en_stable-2.0.0.tar.gz\n",
        "!gunzip ERNIE_Base_en_stable-2.0.0.tar.gz\n",
        "!tar -xvf ERNIE_Base_en_stable-2.0.0.tar\n",
        "!git clone https://github.com/PaddlePaddle/ERNIE.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting paddlepaddle-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/ee/9bd86fe871f38536240b1fdbc4b035bb7478369dcef8805495b7933bef83/paddlepaddle_gpu-1.7.0.post107-cp36-cp36m-manylinux1_x86_64.whl (258.7MB)\n",
            "\u001b[K     |████████████████████████████████| 258.7MB 64kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.13)\n",
            "Collecting scipy<=1.3.1; python_version >= \"3.5\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2MB 130kB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (4.4.1)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.10.0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (2.21.0)\n",
            "Requirement already satisfied: nltk; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.2.5)\n",
            "Collecting funcsigs\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (6.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (0.10.1)\n",
            "Collecting objgraph\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/21/b8ea10bea21a3ecb603ab0a8a59e49282d83eadba16e47464193b0b70dce/objgraph-3.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.12; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (1.17.5)\n",
            "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (3.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (1.12.0)\n",
            "Collecting rarfile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/0b/107dde3f330d04668e126932a09002ac47348841453aa0391634381fa087/rarfile-3.1.tar.gz (121kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 64.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: prettytable in /usr/local/lib/python3.6/dist-packages (from paddlepaddle-gpu) (0.7.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->paddlepaddle-gpu) (45.2.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2019.11.28)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu) (1.1.0)\n",
            "Building wheels for collected packages: rarfile\n",
            "  Building wheel for rarfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rarfile: filename=rarfile-3.1-cp36-none-any.whl size=24908 sha256=2ad49550addbe89f8472d3677b57d41574be67a7017af8bea086ec7d497d223d\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/3c/c8/0215b6a5079492eff3be3f545ae0b0c4a66734c35c9e444eac\n",
            "Successfully built rarfile\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy, funcsigs, objgraph, rarfile, paddlepaddle-gpu\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed funcsigs-1.0.2 objgraph-3.4.1 paddlepaddle-gpu-1.7.0.post107 rarfile-3.1 scipy-1.3.1\n",
            "--2020-03-11 16:40:36--  https://ernie.bj.bcebos.com/ERNIE_Base_en_stable-2.0.0.tar.gz\n",
            "Resolving ernie.bj.bcebos.com (ernie.bj.bcebos.com)... 103.235.46.61\n",
            "Connecting to ernie.bj.bcebos.com (ernie.bj.bcebos.com)|103.235.46.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405413980 (387M) [application/x-gzip]\n",
            "Saving to: ‘ERNIE_Base_en_stable-2.0.0.tar.gz’\n",
            "\n",
            "ERNIE_Base_en_stabl 100%[===================>] 386.63M  30.3MB/s    in 24s     \n",
            "\n",
            "2020-03-11 16:41:01 (16.3 MB/s) - ‘ERNIE_Base_en_stable-2.0.0.tar.gz’ saved [405413980/405413980]\n",
            "\n",
            "ernie_config.json\n",
            "params/\n",
            "params/encoder_layer_4_post_att_layer_norm_scale\n",
            "params/encoder_layer_2_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_2_ffn_fc_1.w_0\n",
            "params/encoder_layer_6_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_7_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_11_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_5_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_1_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_11_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_7_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_1_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_9_ffn_fc_1.b_0\n",
            "params/encoder_layer_4_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_2_ffn_fc_1.b_0\n",
            "params/encoder_layer_7_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_7_post_att_layer_norm_scale\n",
            "params/encoder_layer_6_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_3_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_1_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_10_ffn_fc_0.w_0\n",
            "params/encoder_layer_6_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_3_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_8_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_4_post_att_layer_norm_bias\n",
            "params/pre_encoder_layer_norm_scale\n",
            "params/encoder_layer_2_post_att_layer_norm_scale\n",
            "params/encoder_layer_5_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_ffn_fc_0.b_0\n",
            "params/encoder_layer_4_ffn_fc_1.b_0\n",
            "params/encoder_layer_10_ffn_fc_1.w_0\n",
            "params/encoder_layer_2_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_3_post_att_layer_norm_bias\n",
            "params/encoder_layer_1_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_0_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_8_ffn_fc_1.b_0\n",
            "params/encoder_layer_3_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_2_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_6_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_6_post_att_layer_norm_scale\n",
            "params/encoder_layer_0_post_att_layer_norm_scale\n",
            "params/encoder_layer_2_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_5_ffn_fc_1.w_0\n",
            "params/encoder_layer_0_ffn_fc_0.b_0\n",
            "params/encoder_layer_1_post_att_layer_norm_scale\n",
            "params/encoder_layer_6_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_5_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_11_post_att_layer_norm_scale\n",
            "params/encoder_layer_9_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_9_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_0_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_2_ffn_fc_0.w_0\n",
            "params/pos_embedding\n",
            "params/encoder_layer_8_ffn_fc_0.b_0\n",
            "params/encoder_layer_11_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_0_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_9_post_att_layer_norm_bias\n",
            "params/encoder_layer_2_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_9_multi_head_att_key_fc.b_0\n",
            "params/task_embedding\n",
            "params/encoder_layer_10_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_4_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_0_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_10_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_1_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_5_post_att_layer_norm_scale\n",
            "params/encoder_layer_8_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_0_ffn_fc_0.w_0\n",
            "params/encoder_layer_5_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_7_ffn_fc_0.w_0\n",
            "params/encoder_layer_7_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_7_ffn_fc_1.w_0\n",
            "params/encoder_layer_2_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_9_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_9_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_9_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_4_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_11_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_1_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_0_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_6_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_7_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_8_ffn_fc_1.w_0\n",
            "params/encoder_layer_9_ffn_fc_1.w_0\n",
            "params/sent_embedding\n",
            "params/encoder_layer_0_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_6_ffn_fc_0.w_0\n",
            "params/encoder_layer_1_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_6_ffn_fc_1.b_0\n",
            "params/encoder_layer_0_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_5_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_2_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_0_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_9_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_1_ffn_fc_1.w_0\n",
            "params/encoder_layer_0_ffn_fc_1.w_0\n",
            "params/encoder_layer_8_ffn_fc_0.w_0\n",
            "params/encoder_layer_11_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_5_ffn_fc_0.w_0\n",
            "params/pre_encoder_layer_norm_bias\n",
            "params/encoder_layer_6_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_10_ffn_fc_0.b_0\n",
            "params/encoder_layer_6_ffn_fc_1.w_0\n",
            "params/encoder_layer_4_ffn_fc_1.w_0\n",
            "params/encoder_layer_2_ffn_fc_0.b_0\n",
            "params/encoder_layer_5_ffn_fc_0.b_0\n",
            "params/encoder_layer_10_ffn_fc_1.b_0\n",
            "params/pooled_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_8_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_3_ffn_fc_0.b_0\n",
            "params/encoder_layer_11_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_7_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_9_ffn_fc_0.w_0\n",
            "params/encoder_layer_9_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_0_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_7_post_att_layer_norm_bias\n",
            "params/encoder_layer_3_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_11_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_5_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_0_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_4_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_3_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_3_multi_head_att_query_fc.w_0\n",
            "params/encoder_layer_11_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_8_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_4_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_6_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_9_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_3_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_6_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_9_ffn_fc_0.b_0\n",
            "params/encoder_layer_10_post_att_layer_norm_scale\n",
            "params/encoder_layer_11_ffn_fc_0.b_0\n",
            "params/pooled_fc.b_0\n",
            "params/encoder_layer_2_post_att_layer_norm_bias\n",
            "params/encoder_layer_8_multi_head_att_output_fc.w_0\n",
            "params/encoder_layer_1_ffn_fc_0.w_0\n",
            "params/encoder_layer_4_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_8_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_10_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_6_ffn_fc_0.b_0\n",
            "params/encoder_layer_5_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_3_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_3_ffn_fc_1.b_0\n",
            "params/encoder_layer_10_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_10_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_8_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_8_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_11_post_att_layer_norm_bias\n",
            "params/encoder_layer_8_post_att_layer_norm_scale\n",
            "params/encoder_layer_10_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_ffn_fc_0.w_0\n",
            "params/encoder_layer_1_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_4_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_11_ffn_fc_0.w_0\n",
            "params/encoder_layer_3_post_att_layer_norm_scale\n",
            "params/encoder_layer_10_post_ffn_layer_norm_bias\n",
            "params/encoder_layer_11_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_query_fc.b_0\n",
            "params/encoder_layer_6_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_8_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_0_ffn_fc_1.b_0\n",
            "params/encoder_layer_9_post_att_layer_norm_scale\n",
            "params/word_embedding\n",
            "params/encoder_layer_3_ffn_fc_1.w_0\n",
            "params/encoder_layer_11_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_3_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_11_ffn_fc_1.b_0\n",
            "params/encoder_layer_2_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_3_ffn_fc_0.w_0\n",
            "params/encoder_layer_5_ffn_fc_1.b_0\n",
            "params/encoder_layer_1_ffn_fc_0.b_0\n",
            "params/encoder_layer_1_ffn_fc_1.b_0\n",
            "params/encoder_layer_8_post_att_layer_norm_bias\n",
            "params/encoder_layer_7_ffn_fc_0.b_0\n",
            "params/encoder_layer_1_multi_head_att_value_fc.b_0\n",
            "params/encoder_layer_2_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_7_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_3_post_ffn_layer_norm_scale\n",
            "params/encoder_layer_11_ffn_fc_1.w_0\n",
            "params/encoder_layer_1_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_0_post_att_layer_norm_bias\n",
            "params/encoder_layer_4_multi_head_att_key_fc.b_0\n",
            "params/encoder_layer_2_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_4_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_8_multi_head_att_key_fc.w_0\n",
            "params/encoder_layer_10_multi_head_att_output_fc.b_0\n",
            "params/encoder_layer_7_ffn_fc_1.b_0\n",
            "params/encoder_layer_1_post_att_layer_norm_bias\n",
            "params/encoder_layer_9_multi_head_att_value_fc.w_0\n",
            "params/encoder_layer_6_post_ffn_layer_norm_bias\n",
            "vocab.txt\n",
            "Cloning into 'ERNIE'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 1392 (delta 0), reused 3 (delta 0), pack-reused 1386\u001b[K\n",
            "Receiving objects: 100% (1392/1392), 16.05 MiB | 3.91 MiB/s, done.\n",
            "Resolving deltas: 100% (802/802), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_1rIRFGZXUi",
        "colab_type": "text"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GLnT6rmZWcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiD_pnTGX3H1",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6rCMa1fZB2u",
        "colab_type": "code",
        "outputId": "2714cc76-b645-4f25-a099-75cb201e2f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "train=pd.read_csv('https://raw.githubusercontent.com/talhaanwarch/Offensive-Language-Detection/master/Data/olid-training-v1.0.tsv',sep='\\t')\n",
        "train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  ... subtask_b subtask_c\n",
              "0  86426  @USER She should ask a few native Americans wh...  ...       UNT       NaN\n",
              "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...  ...       TIN       IND\n",
              "2  16820  Amazon is investigating Chinese employees who ...  ...       NaN       NaN\n",
              "3  62688  @USER Someone should'veTaken\" this piece of sh...  ...       UNT       NaN\n",
              "4  43605  @USER @USER Obama wanted liberals &amp; illega...  ...       NaN       NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgEyqQOJS0IV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mapping = {'OFF': 1, 'NOT': 0}\n",
        "train['subtask_a']=train['subtask_a'].map(mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtdffxRTTZTi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "2de44b12-e3b0-4bb6-d29f-48d588259dfc"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>1</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>1</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  ...  subtask_b subtask_c\n",
              "0  86426  @USER She should ask a few native Americans wh...  ...        UNT       NaN\n",
              "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...  ...        TIN       IND\n",
              "2  16820  Amazon is investigating Chinese employees who ...  ...        NaN       NaN\n",
              "3  62688  @USER Someone should'veTaken\" this piece of sh...  ...        UNT       NaN\n",
              "4  43605  @USER @USER Obama wanted liberals &amp; illega...  ...        NaN       NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnwspcURZQq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['tweet']=train['tweet'].str.replace('@USER', \"\") \n",
        "train['tweet']=train['tweet'].str.replace('\\d+', '')\n",
        "train['tweet']=train['tweet'].str.lower()\n",
        "train['tweet']=train['tweet'].str.replace('[^\\w\\s]','')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwRZy_M0T_zY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "b34517a7-ee9f-4f9b-e644-8ddda84d530c"
      },
      "source": [
        "train=train.iloc[:,1:3]\n",
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>go home youre drunk  maga trump  url</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>obama wanted liberals amp illegals to move i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  subtask_a\n",
              "0   she should ask a few native americans what th...          1\n",
              "1               go home youre drunk  maga trump  url          1\n",
              "2  amazon is investigating chinese employees who ...          0\n",
              "3   someone shouldvetaken this piece of shit to a...          1\n",
              "4    obama wanted liberals amp illegals to move i...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ley4q_XzUBOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train,val=train_test_split(train,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b_7Ler9UUEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "66ae4f25-eadb-414d-e011-d11697761590"
      },
      "source": [
        "test_data=pd.read_csv('https://raw.githubusercontent.com/talhaanwarch/Offensive-Language-Detection/master/Data/testset-levela.tsv',sep='\\t')\n",
        "test_label=pd.read_csv('https://raw.githubusercontent.com/talhaanwarch/Offensive-Language-Detection/master/Data/labels-levela.csv',header=None )\n",
        "test=pd.concat([test_data,test_label],axis=1)\n",
        "test=test.drop(test.columns[2],axis=1)\n",
        "test.columns=['id','tweet','subtask_a']\n",
        "test_id=test.pop('id')\n",
        "test.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#Watching #Boomer getting the news that she is...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet subtask_a\n",
              "0  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       OFF\n",
              "1  #ConstitutionDay is revered by Conservatives, ...       NOT\n",
              "2  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...       NOT\n",
              "3  #Watching #Boomer getting the news that she is...       NOT\n",
              "4  #NoPasaran: Unity demo to oppose the far-right...       OFF"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nek_Y_GFU2Ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mapping = {'OFF': 1, 'NOT': 0}\n",
        "test['subtask_a']=test['subtask_a'].map(mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KCRNjwaTpoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ff33da4-5636-4904-8020-285b6dbea7b0"
      },
      "source": [
        "print(len(train), len(val), len(test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10592 2648 860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiKmwMedbJSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.columns=['text_a','label']\n",
        "val.columns=['text_a','label']\n",
        "test.columns=['text_a','label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH47JKB1LpvP",
        "colab_type": "code",
        "outputId": "d50c1e5a-e366-4052-d060-12ed73474e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train.to_csv('train.tsv', index=False, sep='\\t')\n",
        "val.to_csv('dev.tsv', index=False, sep='\\t')\n",
        "test.to_csv('test.tsv', index=False, sep='\\t')\n",
        "print(\"saved\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv-bhT97brgE",
        "colab_type": "text"
      },
      "source": [
        "## Get environment ready for train and testing\n",
        "\n",
        "### -create new folder for dataset\n",
        "### -set path for model parameters and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdYqqG4_bq5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p 'dataset/SST-2'\n",
        "!mkdir -p parameters/params\n",
        "!mv train.tsv dataset/SST-2/\n",
        "!mv dev.tsv dataset/SST-2/\n",
        "!mv test.tsv dataset/SST-2/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4segSL-NdV_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/params parameters/params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bQdjv7Ce_dZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv dataset/ ERNIE/\n",
        "!mv parameters/ ERNIE/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0XGR5piSx-f",
        "colab_type": "text"
      },
      "source": [
        "## Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPHtxNo9Zjnh",
        "colab_type": "code",
        "outputId": "96cde88a-2430-452c-c1ad-e427f70d295a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir('ERNIE/')\n",
        "os.environ['TASK_DATA_PATH']='dataset'\n",
        "os.environ['MODEL_PATH']='parameters/params'\n",
        "print(os.getcwd())\n",
        "!sh script/en_glue/ernie_base/SST-2/task.sh"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ERNIE\n",
            "script/en_glue/ernie_base/SST-2/task.sh: 8: script/en_glue/ernie_base/SST-2/task.sh: [[: not found\n",
            "2020-03-11 16:41:59,217-INFO: -----------  Configuration Arguments -----------\n",
            "[INFO] 2020-03-11 16:41:59,217 [     args.py:   68]:\t-----------  Configuration Arguments -----------\n",
            "2020-03-11 16:41:59,217-INFO: batch_size: 32\n",
            "[INFO] 2020-03-11 16:41:59,217 [     args.py:   70]:\tbatch_size: 32\n",
            "2020-03-11 16:41:59,217-INFO: checkpoints: ./checkpoints\n",
            "[INFO] 2020-03-11 16:41:59,217 [     args.py:   70]:\tcheckpoints: ./checkpoints\n",
            "2020-03-11 16:41:59,217-INFO: chunk_scheme: IOB\n",
            "[INFO] 2020-03-11 16:41:59,217 [     args.py:   70]:\tchunk_scheme: IOB\n",
            "2020-03-11 16:41:59,217-INFO: decr_every_n_nan_or_inf: 2\n",
            "[INFO] 2020-03-11 16:41:59,217 [     args.py:   70]:\tdecr_every_n_nan_or_inf: 2\n",
            "2020-03-11 16:41:59,217-INFO: decr_ratio: 0.8\n",
            "[INFO] 2020-03-11 16:41:59,217 [     args.py:   70]:\tdecr_ratio: 0.8\n",
            "2020-03-11 16:41:59,217-INFO: dev_set: dataset/SST-2/dev.tsv\n",
            "[INFO] 2020-03-11 16:41:59,217 [     args.py:   70]:\tdev_set: dataset/SST-2/dev.tsv\n",
            "2020-03-11 16:41:59,218-INFO: diagnostic: None\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tdiagnostic: None\n",
            "2020-03-11 16:41:59,218-INFO: diagnostic_save: None\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tdiagnostic_save: None\n",
            "2020-03-11 16:41:59,218-INFO: do_lower_case: True\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tdo_lower_case: True\n",
            "2020-03-11 16:41:59,218-INFO: do_test: True\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tdo_test: True\n",
            "2020-03-11 16:41:59,218-INFO: do_train: True\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tdo_train: True\n",
            "2020-03-11 16:41:59,218-INFO: do_val: True\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tdo_val: True\n",
            "2020-03-11 16:41:59,218-INFO: doc_stride: 128\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tdoc_stride: 128\n",
            "2020-03-11 16:41:59,218-INFO: enable_ce: False\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tenable_ce: False\n",
            "2020-03-11 16:41:59,218-INFO: epoch: 4\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tepoch: 4\n",
            "2020-03-11 16:41:59,218-INFO: ernie_config_path: script/en_glue/ernie_base/ernie_config.json\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\ternie_config_path: script/en_glue/ernie_base/ernie_config.json\n",
            "2020-03-11 16:41:59,218-INFO: for_cn: False\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tfor_cn: False\n",
            "2020-03-11 16:41:59,218-INFO: in_tokens: False\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tin_tokens: False\n",
            "2020-03-11 16:41:59,218-INFO: incr_every_n_steps: 100\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tincr_every_n_steps: 100\n",
            "2020-03-11 16:41:59,218-INFO: incr_ratio: 2.0\n",
            "[INFO] 2020-03-11 16:41:59,218 [     args.py:   70]:\tincr_ratio: 2.0\n",
            "2020-03-11 16:41:59,219-INFO: init_checkpoint: None\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tinit_checkpoint: None\n",
            "2020-03-11 16:41:59,219-INFO: init_loss_scaling: 102400\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tinit_loss_scaling: 102400\n",
            "2020-03-11 16:41:59,219-INFO: init_pretraining_params: parameters/params/params\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tinit_pretraining_params: parameters/params/params\n",
            "2020-03-11 16:41:59,219-INFO: is_classify: True\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tis_classify: True\n",
            "2020-03-11 16:41:59,219-INFO: is_distributed: False\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tis_distributed: False\n",
            "2020-03-11 16:41:59,219-INFO: is_regression: False\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tis_regression: False\n",
            "2020-03-11 16:41:59,219-INFO: label_map_config: None\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tlabel_map_config: None\n",
            "2020-03-11 16:41:59,219-INFO: learning_rate: 2e-05\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tlearning_rate: 2e-05\n",
            "2020-03-11 16:41:59,219-INFO: lr_scheduler: linear_warmup_decay\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tlr_scheduler: linear_warmup_decay\n",
            "2020-03-11 16:41:59,219-INFO: max_answer_length: 100\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tmax_answer_length: 100\n",
            "2020-03-11 16:41:59,219-INFO: max_query_length: 64\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tmax_query_length: 64\n",
            "2020-03-11 16:41:59,219-INFO: max_seq_len: 128\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tmax_seq_len: 128\n",
            "2020-03-11 16:41:59,219-INFO: metric: simple_accuracy\n",
            "[INFO] 2020-03-11 16:41:59,219 [     args.py:   70]:\tmetric: simple_accuracy\n",
            "2020-03-11 16:41:59,220-INFO: metrics: True\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\tmetrics: True\n",
            "2020-03-11 16:41:59,220-INFO: n_best_size: 20\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\tn_best_size: 20\n",
            "2020-03-11 16:41:59,220-INFO: num_iteration_per_drop_scope: 1\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\tnum_iteration_per_drop_scope: 1\n",
            "2020-03-11 16:41:59,220-INFO: num_labels: 2\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\tnum_labels: 2\n",
            "2020-03-11 16:41:59,220-INFO: predict_batch_size: None\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\tpredict_batch_size: None\n",
            "2020-03-11 16:41:59,220-INFO: random_seed: 1\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\trandom_seed: 1\n",
            "2020-03-11 16:41:59,220-INFO: save_steps: 10000\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\tsave_steps: 10000\n",
            "2020-03-11 16:41:59,220-INFO: shuffle: True\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\tshuffle: True\n",
            "2020-03-11 16:41:59,220-INFO: skip_steps: 10\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\tskip_steps: 10\n",
            "2020-03-11 16:41:59,220-INFO: task_id: 0\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\ttask_id: 0\n",
            "2020-03-11 16:41:59,220-INFO: test_save: output/test_out.{1..5}.2e-5.32.4.tsv\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\ttest_save: output/test_out.{1..5}.2e-5.32.4.tsv\n",
            "2020-03-11 16:41:59,220-INFO: test_set: dataset/SST-2/test.tsv\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\ttest_set: dataset/SST-2/test.tsv\n",
            "2020-03-11 16:41:59,220-INFO: tokenizer: FullTokenizer\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\ttokenizer: FullTokenizer\n",
            "2020-03-11 16:41:59,220-INFO: train_set: dataset/SST-2/train.tsv\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\ttrain_set: dataset/SST-2/train.tsv\n",
            "2020-03-11 16:41:59,220-INFO: use_cuda: True\n",
            "[INFO] 2020-03-11 16:41:59,220 [     args.py:   70]:\tuse_cuda: True\n",
            "2020-03-11 16:41:59,221-INFO: use_dynamic_loss_scaling: True\n",
            "[INFO] 2020-03-11 16:41:59,221 [     args.py:   70]:\tuse_dynamic_loss_scaling: True\n",
            "2020-03-11 16:41:59,221-INFO: use_fast_executor: True\n",
            "[INFO] 2020-03-11 16:41:59,221 [     args.py:   70]:\tuse_fast_executor: True\n",
            "2020-03-11 16:41:59,221-INFO: use_fp16: False\n",
            "[INFO] 2020-03-11 16:41:59,221 [     args.py:   70]:\tuse_fp16: False\n",
            "2020-03-11 16:41:59,221-INFO: use_multi_gpu_test: False\n",
            "[INFO] 2020-03-11 16:41:59,221 [     args.py:   70]:\tuse_multi_gpu_test: False\n",
            "2020-03-11 16:41:59,221-INFO: validation_steps: 800000000000\n",
            "[INFO] 2020-03-11 16:41:59,221 [     args.py:   70]:\tvalidation_steps: 800000000000\n",
            "2020-03-11 16:41:59,221-INFO: verbose: True\n",
            "[INFO] 2020-03-11 16:41:59,221 [     args.py:   70]:\tverbose: True\n",
            "2020-03-11 16:41:59,221-INFO: vocab_path: script/en_glue/ernie_base/vocab.txt\n",
            "[INFO] 2020-03-11 16:41:59,221 [     args.py:   70]:\tvocab_path: script/en_glue/ernie_base/vocab.txt\n",
            "2020-03-11 16:41:59,221-INFO: warmup_proportion: 0.1\n",
            "[INFO] 2020-03-11 16:41:59,221 [     args.py:   70]:\twarmup_proportion: 0.1\n",
            "2020-03-11 16:41:59,221-INFO: weight_decay: 0.0\n",
            "[INFO] 2020-03-11 16:41:59,221 [     args.py:   70]:\tweight_decay: 0.0\n",
            "2020-03-11 16:41:59,221-INFO: ------------------------------------------------\n",
            "[INFO] 2020-03-11 16:41:59,221 [     args.py:   71]:\t------------------------------------------------\n",
            "2020-03-11 16:41:59,221-INFO: attention_probs_dropout_prob: 0.1\n",
            "[INFO] 2020-03-11 16:41:59,221 [    ernie.py:   52]:\tattention_probs_dropout_prob: 0.1\n",
            "2020-03-11 16:41:59,222-INFO: hidden_act: gelu\n",
            "[INFO] 2020-03-11 16:41:59,222 [    ernie.py:   52]:\thidden_act: gelu\n",
            "2020-03-11 16:41:59,222-INFO: hidden_dropout_prob: 0.1\n",
            "[INFO] 2020-03-11 16:41:59,222 [    ernie.py:   52]:\thidden_dropout_prob: 0.1\n",
            "2020-03-11 16:41:59,222-INFO: hidden_size: 768\n",
            "[INFO] 2020-03-11 16:41:59,222 [    ernie.py:   52]:\thidden_size: 768\n",
            "2020-03-11 16:41:59,222-INFO: initializer_range: 0.02\n",
            "[INFO] 2020-03-11 16:41:59,222 [    ernie.py:   52]:\tinitializer_range: 0.02\n",
            "2020-03-11 16:41:59,222-INFO: max_position_embeddings: 512\n",
            "[INFO] 2020-03-11 16:41:59,222 [    ernie.py:   52]:\tmax_position_embeddings: 512\n",
            "2020-03-11 16:41:59,222-INFO: num_attention_heads: 12\n",
            "[INFO] 2020-03-11 16:41:59,222 [    ernie.py:   52]:\tnum_attention_heads: 12\n",
            "2020-03-11 16:41:59,222-INFO: num_hidden_layers: 12\n",
            "[INFO] 2020-03-11 16:41:59,222 [    ernie.py:   52]:\tnum_hidden_layers: 12\n",
            "2020-03-11 16:41:59,222-INFO: sent_type_vocab_size: 4\n",
            "[INFO] 2020-03-11 16:41:59,222 [    ernie.py:   52]:\tsent_type_vocab_size: 4\n",
            "2020-03-11 16:41:59,222-INFO: task_type_vocab_size: 16\n",
            "[INFO] 2020-03-11 16:41:59,222 [    ernie.py:   52]:\ttask_type_vocab_size: 16\n",
            "2020-03-11 16:41:59,222-INFO: vocab_size: 30522\n",
            "[INFO] 2020-03-11 16:41:59,222 [    ernie.py:   52]:\tvocab_size: 30522\n",
            "2020-03-11 16:41:59,222-INFO: ------------------------------------------------\n",
            "[INFO] 2020-03-11 16:41:59,222 [    ernie.py:   53]:\t------------------------------------------------\n",
            "2020-03-11 16:41:59,303-INFO: Device count: 1\n",
            "[INFO] 2020-03-11 16:41:59,303 [run_classifier.py:  103]:\tDevice count: 1\n",
            "2020-03-11 16:41:59,304-INFO: Num train examples: 10592\n",
            "[INFO] 2020-03-11 16:41:59,304 [run_classifier.py:  104]:\tNum train examples: 10592\n",
            "2020-03-11 16:41:59,304-INFO: Max train steps: 1324\n",
            "[INFO] 2020-03-11 16:41:59,304 [run_classifier.py:  105]:\tMax train steps: 1324\n",
            "2020-03-11 16:41:59,304-INFO: Num warmup steps: 132\n",
            "[INFO] 2020-03-11 16:41:59,304 [run_classifier.py:  106]:\tNum warmup steps: 132\n",
            "2020-03-11 16:42:47,230-INFO: Theoretical memory usage in training: 17039.884 - 17851.307 MB\n",
            "[INFO] 2020-03-11 16:42:47,230 [run_classifier.py:  146]:\tTheoretical memory usage in training: 17039.884 - 17851.307 MB\n",
            "W0311 16:42:49.845046   230 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.1, Runtime API Version: 10.0\n",
            "W0311 16:42:50.365989   230 device_context.cc:245] device: 0, cuDNN Version: 7.6.\n",
            "Traceback (most recent call last):\n",
            "  File \"./ernie/run_classifier.py\", line 447, in <module>\n",
            "    main(args)\n",
            "  File \"./ernie/run_classifier.py\", line 205, in main\n",
            "    use_fp16=args.use_fp16)\n",
            "  File \"/content/ERNIE/ernie/utils/init.py\", line 75, in init_pretraining_params\n",
            "    ), \"[%s] cann't be found.\" % pretraining_params_path\n",
            "AssertionError: [parameters/params/params] cann't be found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azjtwZKIkjBl",
        "colab_type": "code",
        "outputId": "275fe67d-983f-4f50-cd2f-1a96e9e41d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!python3 predict_classifier.py -u --ernie_config_path script/en_glue/ernie_base/ernie_config.json --init_check_point checkpoints/"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'predict_classifier.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg1-k9RIH83C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}